# Hybrid Recommendation System

Há»‡ thá»‘ng gá»£i Ã½ sáº£n pháº©m sá»­ dá»¥ng ká»¹ thuáº­t Hybrid káº¿t há»£p **Collaborative Filtering (ALS)** vÃ  **Content-Based (PhoBERT)** cho ná»n táº£ng thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­.

## ğŸ¯ Tá»•ng quan

Há»‡ thá»‘ng cung cáº¥p 2 loáº¡i gá»£i Ã½ chÃ­nh:
- **Homepage**: Gá»£i Ã½ cÃ¡ nhÃ¢n hÃ³a dá»±a trÃªn lá»‹ch sá»­ ngÆ°á»i dÃ¹ng (ALS)
- **Product Detail**: Gá»£i Ã½ sáº£n pháº©m tÆ°Æ¡ng tá»± (Hybrid: 60% Content + 40% Collaborative)


## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
recommend-service/
â”œâ”€â”€ models/                     # Trained ML models
â”‚   â”œâ”€â”€ als_model.pkl          # ALS collaborative filtering
â”‚   â””â”€â”€ phobert_embeddings.pkl # PhoBERT content vectors
â”œâ”€â”€ data/                      # Training datasets
â”‚   â”œâ”€â”€ interactions.csv       # User-item interactions (weight: 1-3)
â”‚   â””â”€â”€ products.csv          # Product metadata
â”‚
â”œâ”€â”€ when_need/                
â”‚   â”œâ”€â”€ check_gpu.py          # GPU availability check
â”‚   â”œâ”€â”€ check_occur.py        # Co-occurrence analysis
â”‚   â””â”€â”€ length_of_text.py     # Text length statistics
â”œâ”€â”€ load_data.py              # Data loading utilities
â”œâ”€â”€ mf.py                     # ALS implementation
â”œâ”€â”€ phoBERT_content.py        # PhoBERT embedding generation
â”œâ”€â”€ eval.py                   # Model evaluation
â”œâ”€â”€ evaluator.py              # Evaluation metrics
â”œâ”€â”€ api.py                    # FastAPI service (Eureka-enabled)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ CÃ i Ä‘áº·t

### 1. YÃªu cáº§u há»‡ thá»‘ng
- Python 3.8+
- CUDA 11.x (optional, cho GPU acceleration)
- MySQL 8.0+ (náº¿u sá»­ dá»¥ng DB thay vÃ¬ CSV)

### 2. CÃ i Ä‘áº·t dependencies

```bash
# Táº¡o virtual environment
python -m venv myenv
source myenv/bin/activate  # Linux/Mac
# hoáº·c 
myenv\Scripts\activate  # Windows

# CÃ i Ä‘áº·t packages
pip install -r requirements.txt
```

### 3. Kiá»ƒm tra GPU (optional)

```bash
python when_need/check_gpu.py
```

## ğŸ“Š Chuáº©n bá»‹ dá»¯ liá»‡u

### Format file CSV

**interactions.csv**:
```csv
user_id,product_id,weight
user_001,prod_123,3
user_002,prod_456,1
```
- `weight`: 1 (click), 2 (add to cart), 3 (purchase)

**products.csv**:
```csv
product_id,name,category,brand,description
prod_123,iPhone 15,Smartphone,Apple,Äiá»‡n thoáº¡i thÃ´ng minh...
```

### Kiá»ƒm tra Ä‘á»™ dÃ i text (cho PhoBERT)

```bash
python when_need/length_of_text.py
```

Äiá»u chá»‰nh `max_length` trong PhoBERT:
- 95th percentile < 256 â†’ dÃ¹ng `max_length=256`
- 95th percentile > 256 â†’ tÄƒng lÃªn 384 hoáº·c 512

## ğŸ”§ Training Models

### 1. Train ALS Model (Collaborative Filtering)

```bash
python mf.py
```

**Hyperparameters** (trong `mf.py`):
```python
AlternatingLeastSquares(
    n_factors=50,        # Sá»‘ chiá»u latent vectors (50-100)
    n_iterations=15,     # Sá»‘ epoch (10-20)
    reg_param=0.01,      # L2 regularization (0.001-0.1)
    alpha=40            # Confidence scaling (10-50)
)
```

**Output**: `models/als_model.pkl` (~50-200MB tÃ¹y dataset size)

### 2. Generate PhoBERT Embeddings (Content-Based)

```bash
python phoBERT_content.py
```

**Output**: `models/phobert_embeddings.pkl` (~500MB-2GB)

**LÆ°u Ã½**: 
- PhoBERT yÃªu cáº§u ~4GB RAM (CPU) hoáº·c ~2GB VRAM (GPU)
- QuÃ¡ trÃ¬nh encode cÃ³ thá»ƒ máº¥t 5-30 phÃºt 

### 3. Evaluation

```bash
python eval.py
```

**Metrics**:
- Hit Rate@10: Tá»· lá»‡ user cÃ³ Ã­t nháº¥t 1 sáº£n pháº©m Ä‘Ãºng trong top 10
- Precision@10: Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh
- NDCG@10: Ranking quality
- Coverage: Tá»· lá»‡ sáº£n pháº©m Ä‘Æ°á»£c recommend
- Diversity: Äa dáº¡ng giá»¯a cÃ¡c sáº£n pháº©m gá»£i Ã½

**Output**: 
- `evaluation_results.pkl`
- `evaluation_summary.csv`
- `evaluation_comparison.png` (biá»ƒu Ä‘á»“ so sÃ¡nh)

**TiÃªu chÃ­ Ä‘áº¡t chuáº©n**:
- Hit Rate > 50%: Tá»‘t
- Precision > 10%: Cháº¥p nháº­n Ä‘Æ°á»£c
- NDCG > 50%: Tá»‘t
- Coverage > 30%: Äá»§ Ä‘a dáº¡ng

## ğŸŒ Cháº¡y API Service

### 1. Cáº¥u hÃ¬nh Eureka (optional)

Sá»­a trong `api.py`:
```python
eureka_client.init(
    eureka_server="http://localhost:8761/eureka",  # Eureka server URL
    app_name="RECOMMEND-SERVICE",
    instance_port=8888
)
```

### 2. Start service

```bash
python api.py
# hoáº·c
uvicorn api:app --host 0.0.0.0 --port 8888 --reload
```

### 3. Test endpoints

**Homepage recommendations** (guest):
```bash
curl "http://localhost:8888/recommend/homepage?top_k=10"
```

**Homepage recommendations** (logged-in):
```bash
curl "http://localhost:8888/recommend/homepage?user_id=user_001&top_k=10"
```

**Product detail recommendations** (hybrid):
```bash
curl "http://localhost:8888/recommend/product-detail/prod_123?user_id=user_001&top_k=10"
```

**Health check**:
```bash
curl "http://localhost:8888/health"
```

**Admin metrics**:
```bash
curl "http://localhost:8888/admin/metrics"
```

**Trigger training** (background job):
```bash
curl -X POST "http://localhost:8888/train" \
  -H "Content-Type: application/json" \
  -d '{"force_retrain_all": false}'
```

## ğŸ“ˆ Monitoring & Tuning

### ALS Hyperparameter Tuning

**Triá»‡u chá»©ng**: Hit Rate tháº¥p (<30%)
- âœ… TÄƒng `alpha=60` (tÄƒng confidence weighting)
- âœ… TÄƒng `n_factors=100` (tÄƒng capacity)
- âœ… Thu tháº­p thÃªm dá»¯ liá»‡u interaction

**Triá»‡u chá»©ng**: Coverage tháº¥p (<10%)
- âœ… Giáº£m `reg_param=0.001` (giáº£m regularization)
- âœ… TÄƒng diversity trong loss function

**Triá»‡u chá»©ng**: Training cháº­m
- âœ… Giáº£m `n_iterations=10`
- âœ… Sá»­ dá»¥ng sparse matrix operations (Ä‘Ã£ implement)

### PhoBERT Optimization

**Memory issues**:
- âœ… Giáº£m `BATCH_SIZE=8` (trong `phoBERT_content.py`)
- âœ… Giáº£m `max_length=128` náº¿u text ngáº¯n

**Similarity khÃ´ng tá»‘t**:
- âœ… Kiá»ƒm tra text preprocessing (xem `when_need/length_of_text.py`)
- âœ… Thá»­ model khÃ¡c: `vinai/phobert-large` (cháº­m hÆ¡n nhÆ°ng chÃ­nh xÃ¡c hÆ¡n)

### Co-occurrence Analysis

Kiá»ƒm tra xem ALS cÃ³ há»c Ä‘Æ°á»£c patterns khÃ´ng:

```bash
python when_need/check_occur.py
```

Náº¿u "NO OVERLAP" nhiá»u â†’ cáº§n thÃªm dá»¯ liá»‡u hoáº·c giáº£m sparsity.

## ğŸ”’ Production Deployment

### 1. Docker (recommended)

```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8888"]
```

```bash
docker build -t recommend-service .
docker run -p 8888:8888 -v $(pwd)/models:/app/models recommend-service
```

### 2. Environment Variables

```bash
export DB_USER=your_user
export DB_PASSWORD=your_password
export DB_HOST=localhost
export DB_NAME=ecommerce
export USE_DB=false  # true náº¿u dÃ¹ng MySQL
```

### 3. Load Balancing

API tá»± Ä‘á»™ng register vá»›i Eureka Server:
- Heartbeat má»—i 30s
- Timeout 90s trÆ°á»›c khi bá»‹ remove
- Health check endpoint: `/health`

### 4. Hot-swapping Models

```bash
# Train models má»›i
python mf.py
python phoBERT_content.py

# API tá»± Ä‘á»™ng reload sau khi training xong (via /train endpoint)
# KhÃ´ng cáº§n restart service
```

## ğŸ› Troubleshooting

### Issue: "Models not loaded"
```bash
# Kiá»ƒm tra models tá»“n táº¡i
ls -lh models/
# Náº¿u thiáº¿u, cháº¡y láº¡i training
python mf.py
python phoBERT_content.py
```

### Issue: "Product not found"
- Kiá»ƒm tra `product_id` format (pháº£i lÃ  string)
- Kiá»ƒm tra product cÃ³ trong `data/products.csv`

### Issue: PhoBERT OOM (Out of Memory)
```python
# Trong phoBERT_content.py, giáº£m batch size
BATCH_SIZE = 8  # hoáº·c 4
```







